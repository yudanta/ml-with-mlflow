mean_fit_time,std_fit_time,mean_score_time,std_score_time,param_clf__alpha,param_clf__loss,param_clf__max_iter,param_clf__penalty,param_clf__random_state,param_clf__shuffle,param_vect__lowercase,param_vect__ngram_range,param_vect__norm,param_vect__stop_words,param_vect__tokenizer,param_vect__use_idf,params,split0_test_score,split1_test_score,split2_test_score,split3_test_score,split4_test_score,mean_test_score,std_test_score,rank_test_score
0.6395687580108642,0.009905897687417523,0.1351781368255615,0.009944730816345972,0.001,hinge,4,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.4583333333333333,0.625,0.625,0.5833333333333333,0.0631906287004296,59
0.6742303848266602,0.029776568447371428,0.12888269424438475,0.04155597933860672,0.001,hinge,4,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4583333333333333,0.5625,0.525,0.06095307849303248,121
0.5249342918395996,0.11957214529868325,0.09209918975830078,0.017208685331942766,0.001,hinge,4,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.4583333333333333,0.625,0.625,0.5833333333333333,0.0631906287004296,59
0.46156744956970214,0.018090512970297568,0.09269943237304687,0.010956793008811826,0.001,hinge,4,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4583333333333333,0.5416666666666666,0.5291666666666667,0.055277079839256664,119
0.34188365936279297,0.009222219371787547,0.08689093589782715,0.00799092926295935,0.001,hinge,4,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.4583333333333333,0.625,0.625,0.5833333333333333,0.0631906287004296,59
0.3707305908203125,0.01864642689084881,0.08607363700866699,0.010032101719545607,0.001,hinge,4,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4583333333333333,0.5625,0.525,0.06095307849303248,121
0.35809102058410647,0.025364718875502894,0.0998201847076416,0.022794315713471017,0.001,hinge,4,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.4583333333333333,0.625,0.625,0.5833333333333333,0.0631906287004296,59
0.3992311477661133,0.019815197951455234,0.10236144065856934,0.016216032825250637,0.001,hinge,4,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4583333333333333,0.5416666666666666,0.5291666666666667,0.055277079839256664,119
0.36168680191040037,0.01878026167182001,0.09658522605895996,0.015286753650662475,0.001,hinge,4,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5625,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.575,0.05034602488997737,81
0.36489267349243165,0.01398534247679807,0.09234228134155273,0.013782294410665889,0.001,hinge,4,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.7083333333333334,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5916666666666667,0.06400954789890508,25
0.3611892223358154,0.02551900922383071,0.08708677291870118,0.006030777542847318,0.001,hinge,4,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5625,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.575,0.05034602488997737,81
0.3660469055175781,0.012103411852048622,0.09840316772460937,0.014541797454142913,0.001,hinge,4,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.7083333333333334,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5916666666666667,0.06400954789890508,25
0.4307690143585205,0.039966095765932845,0.0916254997253418,0.01611579482579705,0.001,hinge,4,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5625,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.575,0.05034602488997737,81
0.43056607246398926,0.07116822386404593,0.10612721443176269,0.017827905355718307,0.001,hinge,4,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.7083333333333334,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5916666666666667,0.06400954789890508,25
0.6784542560577392,0.17778026225978863,0.16917319297790528,0.12976531753303575,0.001,hinge,4,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5625,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.575,0.05034602488997737,81
0.3715683460235596,0.021156435846441363,0.09159717559814454,0.020814829378447326,0.001,hinge,4,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.7083333333333334,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5916666666666667,0.06400954789890508,25
0.7227792263031005,0.2240602899825838,0.21475419998168946,0.14709484085726798,0.001,hinge,8,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.5322302341461181,0.04401185096369164,0.12340216636657715,0.04044902949583414,0.001,hinge,8,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4791666666666667,0.5416666666666666,0.525,0.05496210815947049,121
0.5559732437133789,0.15435302295239553,0.1548079013824463,0.07819322308545669,0.001,hinge,8,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
1.231643009185791,0.3625349567776292,0.163923978805542,0.07746388985977354,0.001,hinge,8,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4791666666666667,0.5625,0.5375,0.0517069735249619,113
0.4310172080993652,0.030745642204064703,0.0913968563079834,0.01478376136779862,0.001,hinge,8,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.5655585289001465,0.1194904696453349,0.08160276412963867,0.009579155631748947,0.001,hinge,8,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4791666666666667,0.5416666666666666,0.525,0.05496210815947049,121
0.46706619262695315,0.10732850630413227,0.13061060905456542,0.05349429055305543,0.001,hinge,8,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.4985061168670654,0.08825794694905449,0.10768084526062012,0.02133617916855047,0.001,hinge,8,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4791666666666667,0.5625,0.5375,0.0517069735249619,113
0.40251898765563965,0.03885774148916806,0.09273681640625,0.010357054845828984,0.001,hinge,8,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5625,0.5208333333333334,0.5416666666666666,0.5625,0.575,0.058333333333333334,81
0.43659119606018065,0.04325305200542421,0.12952179908752443,0.03727440890266006,0.001,hinge,8,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.4292278289794922,0.0515861969583945,0.09797616004943847,0.017978703213290783,0.001,hinge,8,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5625,0.5208333333333334,0.5416666666666666,0.5625,0.575,0.058333333333333334,81
0.3905627727508545,0.025201804666508038,0.10880532264709472,0.03162816990132883,0.001,hinge,8,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.4186397075653076,0.0732752509971122,0.09173541069030762,0.014728482254164421,0.001,hinge,8,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5625,0.5208333333333334,0.5416666666666666,0.5625,0.575,0.058333333333333334,81
0.3297574520111084,0.01162809541602665,0.08709073066711426,0.014041042005306256,0.001,hinge,8,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.6512411594390869,0.14839832125057859,0.2086790084838867,0.02528587240379928,0.001,hinge,8,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5625,0.5208333333333334,0.5416666666666666,0.5625,0.575,0.058333333333333334,81
0.8425150871276855,0.0712131858925563,0.18274917602539062,0.09309342095916891,0.001,hinge,8,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.42288837432861326,0.1174716856223605,0.08027653694152832,0.008871102434791184,0.001,hinge,10,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6458333333333334,0.625,0.5,0.625,0.6875,0.6166666666666667,0.06263873490988713,1
0.417126989364624,0.04633214585285298,0.10337691307067871,0.03744718074202055,0.001,hinge,10,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4791666666666667,0.5416666666666666,0.525,0.05496210815947049,121
0.39466052055358886,0.030659956449479914,0.08070559501647949,0.009289114370863478,0.001,hinge,10,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6458333333333334,0.625,0.5,0.625,0.6875,0.6166666666666667,0.06263873490988713,1
0.379246187210083,0.017214757651733942,0.08181729316711425,0.01570370330544432,0.001,hinge,10,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4791666666666667,0.5416666666666666,0.5333333333333333,0.05034602488997738,117
0.3371262073516846,0.05413545090998585,0.08812379837036133,0.02449947366377564,0.001,hinge,10,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6458333333333334,0.625,0.5,0.625,0.6875,0.6166666666666667,0.06263873490988713,1
0.41363253593444826,0.06892398422428461,0.13177475929260254,0.04719554135187427,0.001,hinge,10,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4791666666666667,0.5416666666666666,0.525,0.05496210815947049,121
0.42768378257751466,0.03603236769227773,0.124210786819458,0.034301998705164975,0.001,hinge,10,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6458333333333334,0.625,0.5,0.625,0.6875,0.6166666666666667,0.06263873490988713,1
0.5456617832183838,0.07834962373730682,0.22638301849365233,0.027814282638646895,0.001,hinge,10,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4791666666666667,0.5416666666666666,0.5333333333333333,0.05034602488997738,117
0.47773122787475586,0.17165784398900424,0.07861299514770508,0.012098537493454216,0.001,hinge,10,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.575,0.048591265790377515,81
0.4049404144287109,0.032432248592951504,0.09460439682006835,0.02745577319090865,0.001,hinge,10,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.38954644203186034,0.03144502373364986,0.0911165714263916,0.01287061836738404,0.001,hinge,10,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.575,0.048591265790377515,81
0.33261542320251464,0.016399462886844865,0.08709979057312012,0.021438384429936546,0.001,hinge,10,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.3878032684326172,0.05024888259685486,0.10262007713317871,0.01839870602739059,0.001,hinge,10,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.575,0.048591265790377515,81
0.37999281883239744,0.0734504072608607,0.17190542221069335,0.06692217791695194,0.001,hinge,10,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.5570156574249268,0.07661765188150077,0.10497231483459472,0.019141184348441847,0.001,hinge,10,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.575,0.048591265790377515,81
0.3913618564605713,0.04581403846909661,0.09071269035339355,0.01330850760562286,0.001,hinge,10,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.329772424697876,0.01860909104787974,0.08114614486694335,0.01367122166542861,0.001,hinge,16,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.625,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.36005845069885256,0.007061679817532121,0.07573399543762208,0.00895885619393709,0.001,hinge,16,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4583333333333333,0.5625,0.525,0.06095307849303248,121
0.35114240646362305,0.01327791790783694,0.07477784156799316,0.010223303873907887,0.001,hinge,16,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.625,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.3605484962463379,0.020030211700478272,0.07664256095886231,0.007678920781522447,0.001,hinge,16,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4583333333333333,0.5625,0.5333333333333334,0.056825757070774405,115
0.3489075183868408,0.010317285556991454,0.07879199981689453,0.011862851878001544,0.001,hinge,16,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.625,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.38309416770935056,0.024725500110722436,0.10839629173278809,0.031144283170655606,0.001,hinge,16,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.4791666666666667,0.4583333333333333,0.5625,0.525,0.06095307849303248,121
0.4779665946960449,0.055653002447951204,0.11740608215332031,0.021287563816683553,0.001,hinge,16,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.625,0.5,0.625,0.6875,0.6083333333333333,0.06095307849303248,7
0.4946923732757568,0.09626978701352523,0.1031494140625,0.013377601591594339,0.001,hinge,16,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5208333333333334,0.4583333333333333,0.5625,0.5333333333333334,0.056825757070774405,115
0.4011026382446289,0.006298295463575234,0.10729436874389649,0.010655276204004147,0.001,hinge,16,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5625,0.026352313834736504,97
0.4026786804199219,0.0231599889722444,0.08931193351745606,0.009419894355516241,0.001,hinge,16,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.3532859325408936,0.017004201411558922,0.07550458908081055,0.011538095281716126,0.001,hinge,16,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5625,0.026352313834736504,97
0.32980785369873045,0.018213125552850176,0.07429947853088378,0.011445156938535955,0.001,hinge,16,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.317111873626709,0.013768613099797976,0.07189378738403321,0.008931562085221197,0.001,hinge,16,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5625,0.026352313834736504,97
0.323732852935791,0.007892489302748397,0.08365817070007324,0.01662441198456975,0.001,hinge,16,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.5062962532043457,0.21531918262207467,0.11097860336303711,0.07051082451239614,0.001,hinge,16,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5625,0.026352313834736504,97
0.7780981540679932,0.09592844085072917,0.15974316596984864,0.05431538991673678,0.001,hinge,16,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.001, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5208333333333334,0.6041666666666666,0.5625,0.5875,0.056519416526043885,33
0.43241157531738283,0.1239023636946653,0.10286388397216797,0.009982595382906414,0.01,hinge,4,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.5,0.5416666666666666,0.6458333333333334,0.5791666666666667,0.05170697352496191,73
0.36908998489379885,0.09184189944166238,0.09967122077941895,0.02261097226262484,0.01,hinge,4,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5208333333333334,0.5208333333333334,0.5416666666666666,0.6041666666666666,0.5625,0.043700368673756304,97
0.5499658107757568,0.054823955332768,0.110390043258667,0.01709347354057955,0.01,hinge,4,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.5,0.5416666666666666,0.6458333333333334,0.5791666666666667,0.05170697352496191,73
0.46520247459411623,0.032879459686299,0.10909662246704102,0.013191601268875386,0.01,hinge,4,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5208333333333334,0.5,0.5416666666666666,0.6041666666666666,0.5583333333333333,0.04823265376162593,111
0.3999977111816406,0.03321642194671443,0.09604892730712891,0.035983050216933286,0.01,hinge,4,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.5,0.5416666666666666,0.6458333333333334,0.5791666666666667,0.05170697352496191,73
0.37714509963989257,0.01975703657423597,0.07929692268371583,0.00975832689448415,0.01,hinge,4,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5208333333333334,0.5208333333333334,0.5416666666666666,0.6041666666666666,0.5625,0.043700368673756304,97
0.46235084533691406,0.13365534117613964,0.0895765781402588,0.01593449178864403,0.01,hinge,4,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6041666666666666,0.6041666666666666,0.5,0.5416666666666666,0.6458333333333334,0.5791666666666667,0.05170697352496191,73
0.5080772876739502,0.09776797473873987,0.10659928321838379,0.03705663906792444,0.01,hinge,4,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5208333333333334,0.5,0.5416666666666666,0.6041666666666666,0.5583333333333333,0.04823265376162593,111
0.38149046897888184,0.004399288486236729,0.07928194999694824,0.009369293012628661,0.01,hinge,4,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5833333333333334,0.4791666666666667,0.5208333333333334,0.6666666666666666,0.5875,0.08057949835755714,33
0.35249013900756837,0.01336384821574062,0.0732414722442627,0.010105148447182709,0.01,hinge,4,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6458333333333334,0.5208333333333334,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.5625,0.04750730937913076,97
0.3413440227508545,0.01594171795554703,0.08433284759521484,0.015791687086052754,0.01,hinge,4,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5625,0.4791666666666667,0.5,0.625,0.5708333333333334,0.0775044801572428,93
0.3525667667388916,0.01617744060558202,0.08699827194213867,0.01765977856395685,0.01,hinge,4,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6458333333333334,0.5208333333333334,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.5625,0.04750730937913076,97
0.32306728363037107,0.010901271596294355,0.128975772857666,0.07782594641636324,0.01,hinge,4,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5833333333333334,0.4791666666666667,0.5208333333333334,0.6666666666666666,0.5875,0.08057949835755714,33
0.5194622039794922,0.1443937041029607,0.08932781219482422,0.013516461314226302,0.01,hinge,4,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6458333333333334,0.5208333333333334,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.5625,0.04750730937913076,97
0.34529757499694824,0.010430792849930282,0.077030611038208,0.006529903622528491,0.01,hinge,4,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6875,0.5625,0.4791666666666667,0.5,0.625,0.5708333333333334,0.0775044801572428,93
0.3436763286590576,0.006658311223488837,0.08502407073974609,0.019713422886237078,0.01,hinge,4,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 4, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6458333333333334,0.5208333333333334,0.5208333333333334,0.5833333333333334,0.5416666666666666,0.5625,0.04750730937913076,97
0.4642859935760498,0.07356657078589589,0.11934199333190917,0.006279024993358029,0.01,hinge,8,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.5833333333333334,0.5416666666666666,0.5416666666666666,0.7291666666666666,0.6041666666666666,0.06972166887783962,19
0.3478592872619629,0.060836576552596514,0.0859689712524414,0.019308282440018667,0.01,hinge,8,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5208333333333334,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5625,0.0372677996249965,97
0.3515038013458252,0.021040460356034806,0.08137435913085937,0.011979631826899258,0.01,hinge,8,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5416666666666666,0.5416666666666666,0.7708333333333334,0.6166666666666666,0.08395600699837455,5
0.33843016624450684,0.0157355171756145,0.08255400657653808,0.016378108854829584,0.01,hinge,8,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5416666666666666,0.5416666666666666,0.6041666666666666,0.5624999999999999,0.04564354645876384,109
0.3278229236602783,0.008782464455122183,0.08154420852661133,0.01589627119339886,0.01,hinge,8,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.5833333333333334,0.5416666666666666,0.5416666666666666,0.7291666666666666,0.6041666666666666,0.06972166887783962,19
0.3375102519989014,0.007912979316795098,0.07822108268737793,0.01581248444081241,0.01,hinge,8,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5208333333333334,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5625,0.0372677996249965,97
0.34091548919677733,0.00963356827975314,0.08471312522888183,0.01353872567267295,0.01,hinge,8,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5416666666666666,0.5416666666666666,0.7708333333333334,0.6166666666666666,0.08395600699837455,5
0.3930075168609619,0.02463761096029286,0.10124678611755371,0.01368407798261321,0.01,hinge,8,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.625,0.5,0.5416666666666666,0.5416666666666666,0.6041666666666666,0.5624999999999999,0.04564354645876384,109
0.37311592102050783,0.03310172713116012,0.08875160217285157,0.013501742216613172,0.01,hinge,8,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5625,0.5625,0.5416666666666666,0.6875,0.5875,0.05170697352496191,33
0.4679876804351807,0.16228998813643705,0.1155965805053711,0.015000970438423918,0.01,hinge,8,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5416666666666666,0.5,0.6458333333333334,0.5416666666666666,0.5833333333333333,0.07095577652469336,59
0.5796390056610108,0.19252866728579743,0.09440016746520996,0.027126536548526366,0.01,hinge,8,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5416666666666666,0.5625,0.5416666666666666,0.6041666666666666,0.5666666666666667,0.024295632895188764,95
0.3289118766784668,0.008081499766119042,0.08544621467590333,0.015615416415101065,0.01,hinge,8,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5416666666666666,0.5,0.6458333333333334,0.5416666666666666,0.5833333333333333,0.07095577652469336,59
0.3238882064819336,0.01114317406651735,0.08030552864074707,0.013871445594839032,0.01,hinge,8,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5625,0.5625,0.5416666666666666,0.6875,0.5875,0.05170697352496191,33
0.3263701438903809,0.007655630133369535,0.08930339813232421,0.013652628512217704,0.01,hinge,8,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5416666666666666,0.5,0.6458333333333334,0.5416666666666666,0.5833333333333333,0.07095577652469336,59
0.34004712104797363,0.010535840840679142,0.07923731803894044,0.007671977144106958,0.01,hinge,8,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5416666666666666,0.5625,0.5416666666666666,0.6041666666666666,0.5666666666666667,0.024295632895188764,95
0.33869709968566897,0.018343621920663834,0.07430357933044433,0.009877830556963292,0.01,hinge,8,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 8, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5416666666666666,0.5,0.6458333333333334,0.5416666666666666,0.5833333333333333,0.07095577652469336,59
0.3219252586364746,0.013120780178714233,0.08252015113830566,0.014387736836213291,0.01,hinge,10,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5416666666666666,0.5416666666666666,0.6875,0.5999999999999999,0.05496210815947051,21
0.3358773708343506,0.010731141318933806,0.0779942512512207,0.014330335198951497,0.01,hinge,10,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5833333333333334,0.5416666666666666,0.5416666666666666,0.6041666666666666,0.5874999999999999,0.04639803635691685,57
0.39588093757629395,0.027195391254752458,0.0862816333770752,0.02448712662921166,0.01,hinge,10,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5416666666666666,0.5416666666666666,0.6875,0.5999999999999999,0.05496210815947051,21
0.576057243347168,0.10665501082200908,0.08470311164855956,0.0174100425281478,0.01,hinge,10,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5833333333333334,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5833333333333333,0.045643546458763846,59
0.33565359115600585,0.014618849211809407,0.07116117477416992,0.008311835481075789,0.01,hinge,10,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5416666666666666,0.5416666666666666,0.6875,0.5999999999999999,0.05496210815947051,21
0.35957627296447753,0.02209388255222478,0.0863947868347168,0.013339979392229924,0.01,hinge,10,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5833333333333334,0.5416666666666666,0.5416666666666666,0.6041666666666666,0.5874999999999999,0.04639803635691685,57
0.4062933921813965,0.02020913277591135,0.09868507385253907,0.015917155339506085,0.01,hinge,10,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5416666666666666,0.5416666666666666,0.6875,0.5999999999999999,0.05496210815947051,21
0.7317914485931396,0.29013746459606854,0.2751636028289795,0.15345827750121666,0.01,hinge,10,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5833333333333334,0.5416666666666666,0.5416666666666666,0.5833333333333334,0.5833333333333333,0.045643546458763846,59
0.48718986511230467,0.13491286015998646,0.14202651977539063,0.04193778334008544,0.01,hinge,10,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5625,0.5208333333333334,0.6458333333333334,0.5916666666666667,0.044876373392787536,25
0.4775052547454834,0.0916692751420911,0.08122234344482422,0.007887287004897435,0.01,hinge,10,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.3928071022033691,0.06782131737559632,0.13448052406311034,0.06265665815637307,0.01,hinge,10,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5625,0.5208333333333334,0.6458333333333334,0.5916666666666667,0.044876373392787536,25
0.3500330924987793,0.012548351128387513,0.08086051940917968,0.00834094504057306,0.01,hinge,10,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.3665511131286621,0.03747662323884316,0.10640692710876465,0.03266989948166178,0.01,hinge,10,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5625,0.5208333333333334,0.6458333333333334,0.5916666666666667,0.044876373392787536,25
0.4408290863037109,0.05809256917517108,0.08087444305419922,0.009152421784095543,0.01,hinge,10,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.443468713760376,0.1379811816605439,0.1178865909576416,0.061950405909695194,0.01,hinge,10,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.625,0.6041666666666666,0.5625,0.5208333333333334,0.6458333333333334,0.5916666666666667,0.044876373392787536,25
0.3700998783111572,0.0666434610367745,0.09152021408081054,0.024007681560283115,0.01,hinge,10,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 10, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.41521258354187013,0.05888418025065925,0.09805483818054199,0.02209761328835853,0.01,hinge,16,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5833333333333334,0.5208333333333334,0.5833333333333334,0.6666666666666666,0.6041666666666667,0.05590169943749471,15
0.3111076831817627,0.008076738452838699,0.07521696090698242,0.0083828749267919,0.01,hinge,16,l2,13,True,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.625,0.5833333333333333,0.052704627669472995,59
0.43779692649841306,0.14931293463989107,0.11714954376220703,0.060782278544961876,0.01,hinge,16,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5625,0.5208333333333334,0.5833333333333334,0.6875,0.6041666666666667,0.06319062870042957,15
0.4488818645477295,0.10851695256736163,0.08953218460083008,0.03346043641234557,0.01,hinge,16,l2,13,True,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.6041666666666666,0.5791666666666666,0.049999999999999996,77
0.31468896865844725,0.03198045787769576,0.07356009483337403,0.014601883614521262,0.01,hinge,16,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5833333333333334,0.5208333333333334,0.5833333333333334,0.6666666666666666,0.6041666666666667,0.05590169943749471,15
0.31943421363830565,0.013651544893169863,0.0749812126159668,0.013266249199222181,0.01,hinge,16,l2,13,True,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.625,0.5833333333333333,0.052704627669472995,59
0.358640193939209,0.020980496909387525,0.08598213195800782,0.014944871275016921,0.01,hinge,16,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.6666666666666666,0.5625,0.5208333333333334,0.5833333333333334,0.6875,0.6041666666666667,0.06319062870042957,15
0.32711362838745117,0.01452408790033881,0.07219996452331542,0.011585031907354425,0.01,hinge,16,l2,13,True,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': True, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6666666666666666,0.5416666666666666,0.5416666666666666,0.5416666666666666,0.6041666666666666,0.5791666666666666,0.049999999999999996,77
0.31285672187805175,0.01174961990150986,0.07434301376342774,0.008939280975658423,0.01,hinge,16,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5625,0.6041666666666666,0.5416666666666666,0.625,0.5833333333333333,0.029462782549439483,59
0.46065030097961424,0.07327733377200729,0.07346820831298828,0.00983660096483654,0.01,hinge,16,l2,13,False,True,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.33438749313354493,0.01062038176481207,0.07689685821533203,0.006698778747093002,0.01,hinge,16,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5625,0.6041666666666666,0.5416666666666666,0.6041666666666666,0.5791666666666666,0.02429563289518875,77
0.33162784576416016,0.012970631504580863,0.07325549125671386,0.009226438651329761,0.01,hinge,16,l2,13,False,True,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': True, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.32146224975585935,0.030241449390593072,0.0726733684539795,0.007867524322931852,0.01,hinge,16,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5625,0.6041666666666666,0.5416666666666666,0.625,0.5833333333333333,0.029462782549439483,59
0.32436347007751465,0.008533168157168659,0.07738556861877441,0.011169885308228274,0.01,hinge,16,l2,13,False,False,"(1, 1)",,,<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
0.33644938468933105,0.011297021290908794,0.07665257453918457,0.007397618553406647,0.01,hinge,16,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,False,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': False}",0.5833333333333334,0.5625,0.6041666666666666,0.5416666666666666,0.6041666666666666,0.5791666666666666,0.02429563289518875,77
0.2969806671142578,0.032892695253627376,0.0591313362121582,0.01933711780057044,0.01,hinge,16,l2,13,False,False,"(1, 1)",,"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""]",<function tokenizer_porter at 0x12535b820>,True,"{'clf__alpha': 0.01, 'clf__loss': 'hinge', 'clf__max_iter': 16, 'clf__penalty': 'l2', 'clf__random_state': 13, 'clf__shuffle': False, 'vect__lowercase': False, 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', ""you're"", ""you've"", ""you'll"", ""you'd"", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', ""she's"", 'her', 'hers', 'herself', 'it', ""it's"", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', ""that'll"", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', ""don't"", 'should', ""should've"", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', ""aren't"", 'couldn', ""couldn't"", 'didn', ""didn't"", 'doesn', ""doesn't"", 'hadn', ""hadn't"", 'hasn', ""hasn't"", 'haven', ""haven't"", 'isn', ""isn't"", 'ma', 'mightn', ""mightn't"", 'mustn', ""mustn't"", 'needn', ""needn't"", 'shan', ""shan't"", 'shouldn', ""shouldn't"", 'wasn', ""wasn't"", 'weren', ""weren't"", 'won', ""won't"", 'wouldn', ""wouldn't""], 'vect__tokenizer': <function tokenizer_porter at 0x12535b820>, 'vect__use_idf': True}",0.6875,0.5625,0.5,0.6458333333333334,0.5416666666666666,0.5875,0.06897060565519521,33
